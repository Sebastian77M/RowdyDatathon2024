# -*- coding: utf-8 -*-
"""RowdyDatathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o1QxNpWgSq0-tXc0yk3681K5qzSpHlxP

Your report must address the following:
 - A detailed description of monarch butterfly population fluctuations.
 - An investigation of factors that may be contributing to these population
changes, and the potential consequences for human well-being.
 - A recommendation for resource allocation, prioritizing the most significant
factors identified in your analysis.
 - A focused analysis of the monarch butterfly migration through Texas, with
comparisons to other states.
Your team will deliver an executive report supported by an appendix containing
technical details.

# Potential causes for monarch butterfly decline

> Add blockquote


- Increased use of pesticides
- Decrease of resources
- Habitat loss
- Climate change
- Pesticide use
- Change in agricultural practices
- Habitat destruction destroys milkweed which catepillars feed on
- Mismatch between monarchs and available resources due to warmer temperature
"""

!pip install autoviz
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings as wr
wr.filterwarnings('ignore')

"""# Why the issue is important

- Increased Food Prices
- Manual Pollination Cost
- Loss of Ecosystem Services
- Impact on animal products
- Manual Pollination Cost
- Loss of Ecosystem Services
- Impact on Animal Products
- Nutritional Impacts
- Economic Impacts

# New Section
"""

df = pd.read_csv("USDA_PDP_AnalyticalResults.csv")

df.describe(include=object)

df.columns.tolist()

df.shape # 48842 rows by 15 columns

df.dtypes # All the different data types for the dataframe

print(df['Commod'].unique())

print(df['Pesticide Name'].unique())

"""# Web Scraping"""

'''import requests
from bs4 import BeautifulSoup

# Load the website content
url = "https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2024"
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table in the HTML (adjust selector to match the table on the site)
table = soup.find('table')

# Use Pandas to parse the HTML table
df = pd.read_html(str(table))[0]  # Assuming the table is the first one on the page

# Save the table as a CSV file
df.to_csv('output_table.csv', index=False)
'''

"""# Journey North CSV"""

df1 = pd.read_csv("output_table.csv")
df1 = df1.drop(columns=['Image'])

df1.tail()



print(df['Date'].unique())

df1.to_csv('JourneyNorth_updated.csv', index=False)

import pandas as pd
import requests

# Load your CSV file with town, state, latitude, and longitude information
input_csv = 'your_data.csv'  # Replace with your actual CSV file path
df = pd.read_csv(input_csv)

# Print the column names to check their actual names
print("Column names:", df.columns)

# Remove leading/trailing whitespace from column names
df.columns = df.columns.str.strip()

# Function to get county from latitude and longitude using US Census Geocoder
def get_county_from_coords(latitude, longitude):
    url = "https://geocoding.geo.census.gov/geocoder/geographies/coordinates"
    params = {
        'x': longitude,  # Longitude first
        'y': latitude,   # Latitude second
        'benchmark': 'Public_AR_Current',  # Use the current address benchmark
        'vintage': 'Current_Current',  # Use the current vintage of data
        'format': 'json'
    }

    try:
        response = requests.get(url, params=params)
        response.raise_for_status()  # Raise an error for bad responses
        data = response.json()

        # Debugging: Print the response for each request
        print(f"Request for ({latitude}, {longitude}): {data}")

        if 'result' in data and 'geographies' in data['result']:
            # Extract county information from the first match
            county = data['result']['geographies']['Counties'][0]['NAME']
            return county

    except Exception as e:
        print(f"Error retrieving county for ({latitude}, {longitude}): {e}")
        return None

# Create a new column in the DataFrame for counties using latitude and longitude
df['County'] = df.apply(lambda row: get_county_from_coords(row['Latitude'], row['Longitude']), axis=1)

# Save the updated DataFrame to a new CSV file
output_csv = 'output_with_counties.csv'  # Change the output filename as needed
df.to_csv(output_csv, index=False)

print(f"Data with counties has been saved to '{output_csv}'")